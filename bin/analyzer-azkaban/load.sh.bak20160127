#!/bin/bash
#获取配置文件通用方法
GetConf(){    
    section=$(echo $1 | cut -d '.' -f 1)    
    key=$(echo $1 | cut -d '.' -f 2)    
    sed -n "/\[$section\]/,/\[.*\]/{    
     /^\[.*\]/d    
     /^[ \t]*$/d    
     /^$/d    
     /^#.*$/d    
     s/^[ \t]*$key[ \t]*=[ \t]*\(.*\)[ \t]*/\1/p    
    }" ~/bin/analyzer-azkaban/conf/sys_conf.ini    
}
#初始化路径配置
app_home=$(GetConf "local.app_home")
src_logs=$(GetConf "local.src_logs")
mkdir -p ${src_logs}
meta_logs=$(GetConf "local.meta_logs")
mkdir -p ${meta_logs}
host=$(GetConf "remote.host")
uname=$(GetConf "remote.uname")
remote_root=$(GetConf "remote.root")
if   [   $#   -lt 2     ]
then
    echo "usage: sh load_data.sh <date> <log_type> <run_type>"
else
hour=""
hosts_ip=""
sub_dir=""
log_type=$2
if [ $1 = "hour_ago" ]
then
	hour=`date '-d 1 hour ago' +%Y%m%d%H`
elif [ $1 = "day_ago" ]
then
	hour=`date '-d 1 day ago' +%Y%m%d`
else
	hour=$1
fi

echo "hour:"${hour}
day=${hour:0:8}
local_dir="${src_logs}/${log_type}/${day}"
mkdir -p  ${local_dir}
log_file="*${hour}*.log"

stime=$(date +%s -d 'now')
#根据日志类型,指定查找的目录
if [ ${log_type} = "detail" ]
then
	root_dir="/disk3/YH_DATA/DATA/web2.0/detail/sediment"
        echo  ${uname}@${host}:${root_dir}/${log_file}
        scp ${uname}@${host}:${root_dir}/${log_file} ${local_dir}
fi
if [ ${log_type} = "biz_web" ]
then
	root_dir="/disk3/YH_DATA/DATA/web2.0"
	sub_dir="info"
	hosts_ip=""
	echo  ${uname}@${host}:${root_dir}/${sub_dir}/${log_file}
   	scp ${uname}@${host}:${root_dir}/${sub_dir}/${log_file} ${local_dir}
fi
if [ ${log_type} = "biz_intf"  ]
then
	#网厅2.0业务接口日志目录
	root_dir="/disk3/YH_DATA/DATA/web2.0"
	sub_dir="interface"
	echo  ${uname}@${host}:${root_dir}/${sub_dir}/${log_file}
	scp ${uname}@${host}:${root_dir}/${sub_dir}/${log_file} ${local_dir}
	
	#手厅2.0业务接口日志目录
	root_dir="/disk3/YH_DATA/DATA/mobile2.0"
	sub_dir="/interface/*"
	hosts_ip="10.20.34.11 10.20.34.12 10.20.34.13 10.20.34.14 10.142.164.181 10.142.164.182 10.20.8.17 10.20.8.18 10.20.8.19 10.20.8.20 10.142.194.25 10.142.194.26 10.142.194.27 10.142.194.28 10.142.194.29 10.142.194.30 10.142.194.31 10.142.194.32 10.142.194.33 10.142.194.34 "	

	for IP in ${hosts_ip}
	  do
		echo  ${uname}@${host}:${root_dir}/${IP}${sub_dir}/${log_file}
		scp ${uname}@${host}:${root_dir}/${IP}${sub_dir}/${log_file} ${local_dir}
	done
hosts_ip=""
fi
if [ ${log_type} = "ad" ]
then
	root_dir="/disk3/YH_DATA/DATA"
	sub_dir="/app/tomcat/ad/uniAdms"
	hosts_ip="10.20.14.11 10.20.14.12 10.20.14.13 10.20.14.14"	
fi
if [ ${log_type} = "biz_mob" ]
then
	root_dir="/disk3/YH_DATA/DATA/mobile2.0"
	sub_dir="/info/*"
	hosts_ip="10.20.34.11 10.20.34.12 10.20.34.13 10.20.34.14 10.20.34.15 10.20.34.18 10.142.164.181 10.142.164.182 10.20.8.17 10.20.8.18 10.20.8.19 10.20.8.20 10.142.194.25 10.142.194.26 10.142.194.27 10.142.194.28 10.142.194.29 10.142.194.30 10.142.194.31 10.142.194.32 10.142.194.33 10.142.194.34 132.35.102.219 132.35.102.220 132.35.102.239 132.35.102.241 132.35.102.242 132.35.102.243"	
fi
if [ ${log_type} = "client" ]
then
	root_dir="/disk3/YH_DATA/DATA/mobile2.0"
	sub_dir="/client/*"
	hosts_ip="10.20.34.11 10.20.34.12 10.20.34.13 10.20.34.14 10.142.164.181 10.142.164.182 10.20.8.17 10.20.8.18 10.20.8.19 10.20.8.20 10.142.194.25 10.142.194.26 10.142.194.27 10.142.194.28 10.142.194.29 10.142.194.30 10.142.194.31 10.142.194.32 10.142.194.33 10.142.194.34"	
fi
if [ ${log_type} = "fav" ]
then
	root_dir="/disk3/YH_DATA/DATA/mobile2.0"
	sub_dir="/favorite/*"
	hosts_ip="10.20.34.11 10.20.34.12 10.20.34.13 10.20.34.14 10.142.164.181 10.142.164.182 10.20.8.17 10.20.8.18 10.20.8.19 10.20.8.20 10.142.194.25 10.142.194.26 10.142.194.27 10.142.194.28 10.142.194.29 10.142.194.30 10.142.194.31 10.142.194.32 10.142.194.33 10.142.194.34"	
fi
if [ ${log_type} = "push" ]
then
	root_dir="/disk3/YH_DATA/DATA/mobile2.0"
	sub_dir="/*/*"
	hosts_ip="10.10.34.17 10.10.34.18 10.20.34.19 10.20.34.20 10.20.13.13 10.20.13.14"	
fi
 if [ ${log_type} = "pv" ]
then
	root_dir="/disk3/YH_DATA/DATA/mobile2.0"
	sub_dir="/pv/*"
	hosts_ip="10.20.34.11 10.20.34.12 10.20.34.13 10.20.34.14 10.142.194.25 10.142.194.26 10.142.194.27 10.142.194.28 10.142.194.29 10.142.194.30 10.142.194.31 10.142.194.32 10.142.194.33 10.142.194.34"	
fi

if [ ${log_type} = "biz_sms_sfts" ]
then
	root_dir="/disk/ftp/YH_FTP"
	sub_dir="/app/tomcat/logs/simulate/dataplatformlog/data"
	hosts_ip="10.142.132.50 10.142.132.51 10.142.132.52 10.20.39.35 10.20.39.36 10.20.39.37 10.20.39.38 10.20.39.39 10.20.39.40 10.20.39.41 10.20.39.42 10.20.39.43 10.20.39.44 10.20.39.45 10.20.39.46"	
fi
if [ ${log_type} = "biz_sms" ]
then
	root_dir="/disk/ftp/YH_FTP"
	sub_dir="/app/tomcat/logs/sms/dataplatformlog/data"
	sub_dir1="/app/tomcat/logs/sms2/dataplatformlog/data"
        hosts_ip="10.142.132.41 10.142.132.42 10.142.132.43 10.142.132.44 10.142.132.45 10.142.132.46 10.142.132.47 10.142.132.48 10.20.39.11 10.20.39.12 10.20.39.13 10.20.39.14 10.20.39.15 10.20.39.16 10.20.39.17 10.20.39.18 10.20.39.19 10.20.39.20 10.20.39.21 10.20.39.22 10.20.39.23 10.20.39.24 10.20.39.25 10.20.39.26 10.20.39.27 10.20.39.28 10.20.39.29 10.20.39.30"	
	for IP in ${hosts_ip}
	  do
		echo  ${uname}@${host}:${root_dir}/${IP}${sub_dir}/${log_file}
		scp ${uname}@${host}:${root_dir}/${IP}${sub_dir}/${log_file} ${local_dir}
	done
	cd ${local_dir}
	 for files in `ls *.log`
	  do 
		mv $files sms0_${files}
	done
	for IP in ${hosts_ip}
	  do
		echo  ${uname}@${host}:${root_dir}/${IP}${sub_dir1}/${log_file}
		scp ${uname}@${host}:${root_dir}/${IP}${sub_dir1}/${log_file} ${local_dir}
	done

hosts_ip=""
fi

if [ ${log_type} = "nginx" ]
then
	root_dir="/disk3/YH_DATA/DATA"
	sub_dir="/app/nginx/logs"
	sub_dir1="/app/nginx2/logs"
        hosts_ip="10.10.15.11 10.10.15.12 10.10.15.13 10.10.15.14 10.10.15.15 10.10.15.16 10.10.15.17 10.10.15.18 10.30.11.11 10.30.11.12"	
	for IP in ${hosts_ip}
	  do
		echo  ${uname}@${host}:${root_dir}/${IP}${sub_dir}/${log_file}
		scp ${uname}@${host}:${root_dir}/${IP}${sub_dir}/${log_file} ${local_dir}
	done
	cd ${local_dir}
	rm nginx-*.log
	 for files in `ls *.log`
	  do 
		 cat $files | grep -v "f5status" | grep -v "favicon.ico" | grep -v "/js/" | grep -v "/images/" | grep -v ".css" | grep -v ".jpg" | grep -v ".swf" | grep -v "sitestat" >> nginx-${hour}.log
		rm $files
	done
	hosts_ip=""
fi
if [ ${log_type} = "login" ]
then
	root_dir="/disk/ftp/YL_FTP"
	sub_dir="/tyrz/"
	hosts_ip=""

	echo  ${uname}@${host}:${root_dir}/${sub_dir}/${log_file}
   	scp ${uname}@${host}:${root_dir}/${sub_dir}/${log_file} ${local_dir}
fi
if [ ${log_type} = "biz_auto" ]
then
	root_dir="/disk/ftp/YL_FTP"
	sub_dir="/zzfw/"
	hosts_ip=""

	echo  ${uname}@${host}:${root_dir}/${sub_dir}/${log_file}
   	scp ${uname}@${host}:${root_dir}/${sub_dir}/${log_file} ${local_dir}
fi
if [ ${log_type} = "shortaddress" ]
then
	root_dir="/disk/ftp/YH_FTP/shortaddress/input"
	sub_dir="/*"
	hosts_ip="10.10.13.19 10.10.13.20"

echo   ${uname}@${host}:${root_dir}/${IP}${sub_dir}/${log_file} ${local_dir}

fi
if [ ${log_type} = "search" ]
then
	root_dir="/disk/ftp/YH_FTP"
	sub_dir="search"
	hosts_ip=""

echo   ${uname}@${host}:${root_dir}/${IP}${sub_dir}/${log_file} ${local_dir}
  	scp ${uname}@${host}:${root_dir}/${IP}${sub_dir}/${log_file} ${local_dir}
fi
if [ ${log_type} = "biz_intf_v3" ]
then
	root_dir="/disk3/YH_DATA/DATA/web3.0"
	sub_dir="hadooplog"
	hosts_ip=""

echo   ${uname}@${host}:${root_dir}/${sub_dir}/interface${log_file}  ${local_dir}
 scp ${uname}@${host}:${root_dir}/${IP}${sub_dir}/interface${log_file}  ${local_dir}
fi
if [ ${log_type} = "biz_web_v3" ]
then
	root_dir="/disk3/YH_DATA/DATA/web3.0"
	sub_dir="hadooplog"
	hosts_ip=""

echo   ${uname}@${host}:${root_dir}/${sub_dir}/service${log_file}  ${local_dir}
 scp ${uname}@${host}:${root_dir}/${IP}${sub_dir}/service${log_file}  ${local_dir}
fi
#遍历各子目录
for IP in ${hosts_ip}
  do
	echo  ${uname}@${host}:${root_dir}/${IP}${sub_dir}/${log_file}
   	scp ${uname}@${host}:${root_dir}/${IP}${sub_dir}/${log_file} ${local_dir}
done

#统计文件信息
cd ${local_dir}
f_count=`ls ${local_dir}/*${hour}*.log |wc -l`
rec_count=`cat ${local_dir}/*${hour}*.log |wc -l`
f_size=`du -hs`
#打印azkaban监控扫描信息
echo 'HIVE_TABLE_NAME:load-'$2'_'$1
echo 'Exported '$rec_count' records.'

run_type=''
rt=$3
if [[ $rt = "rerun" ]]
then
	run_type="手动执行"
else
	run_type="定时执行"
fi
etime=$(date +%s -d 'now')
echo "["${run_type}"] 总耗时:(秒)"$((($etime-$stime)))
echo "采集日志文件时间:[${hour}],采集类型:[${run_type}],总文件个数:[${f_count}],总记录数:[${rec_count}],总文件大小:["${f_size}"]" >> ${meta_logs}/${log_type}_${day}.meta

#$3='' 定时执行,$3=rerun 重新运行
#sh ${app_home}/analyzer/etl.sh ${hour} ${log_type} $3
fi
